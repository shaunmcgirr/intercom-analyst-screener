\documentclass{article}
\usepackage{hyperref}
\usepackage{pdfpages}
\usepackage{parskip}
\setlength{\parskip}{2mm plus1mm minus1mm}

\begin{document}
\SweaveOpts{concordance=TRUE}

\title{Intercom Analyst Screener}
\author{Shaun McGirr}
\maketitle

\section{Products \& Frameworks}

\subsection{Google's HEART}
\emph{Evaluate Google's HEART framework and list out the main strengths and weaknesses of it, with rationale for your opinion.}

Google's HEART framework\footnote{Available at \url{http://research.google.com/pubs/pub36299.html}} suggests one approach to measuring the user experience and generating data to inform product decisions. It grew from a desire to go beyond blunt measures like `page hits', which are too generic to be informative about what to build next. In the worst case, chasing page hits leads to endless A/B tests with goals disconnected from user experience.

The authors sell HEART as an improvement over traditional small-scale user experience research (observing users complete tasks is costly) and technical metrics under the PULSE framework. It aims to measure user experience as directly as traditional methods, but leverage the wealth of behavioural data generated by web products to measure more with less.

\textbf{Strengths}
\begin{itemize}
  \item The separation of the goals of the business/product/feature from their measurement is a genuine strength. One of the toughest challenges in analytics is to discover the underlying motivation of our stakeholders. As with most technical fields there is a constant urge to choose a solution (eg `maximise weekly active users') before the problem is even well-defined. Beginning the search for metrics by being clear about the goals under each category helps to narrow the field of useful metrics, and makes the eventual choice more trusted.
  \item The inclusion of the `signals' step between definition of goals and metrics is also useful, for a different reason. Common goals for a business or product, like `grow our active user base', lead quite directly to a set of useful metrics, like `change in active users'. The signals step forces an important check: what would success or failure of the goal actually look like? Two common pitfalls of analytics that this can help remedy are: a) trying to build metrics when the relevant data are not actually available, and b) assuming that various stakeholders have a common definition of success.
  \item Some of the technical challenges to achieving good coverage of metrics are fading, as the world becomes more web-page centric and less obsessed with mobile apps or Flash. This means those who find the framework useful for web products should find it more useful over time!
  \item It is built from the experiences of many different product teams at one of the most important web companies, so the expertise it contains is battle-hardened and likely generalisable across many types of products.
\end{itemize}

\textbf{Weaknesses}
\begin{itemize}
  \item Despite being linked by the word HEART, the way the categories in the framework are described suggests they emerged as a way of `binning together' metrics that were \emph{already in use.} If that is true then the development of this framework did not follow its own key strength described above: no goal was defined up front for the framework itself. Beyond `we need more and different measures' the authors don't present a clear case for why these categories and not others. This leads to a deeper problem. Although Happiness, Engagement, Adoption, Retention and Task Success can all be conceptualized and measured, and may even correlate with a generic definition of `good user experience', do they actually represent user experience? In fact, beyond Happiness and Task Success, these categories have little relevance to the way a user experiences a product: Engagement, Adoption and Retention are goals of the product team. Google's (many) decisions to kill off products that were presumably doing OK across these goal categories suggests that the underlying definition of user experience in this framework is undercooked. \textbf{This weakness could be remedied by making a clear case for why these goal categories matter more than any other plausible set. Making a convincing case would rely on having a clear model of how users of a given product make their decisions: in this model, Happiness and Task Success would be inputs, while Engagement, Adoption and Retention are outputs.}
  \item A framework for measuring improvement in user experience should at minimum give some idea of overall progress on achieving a better experience, and make clear the tradeoffs between different goals. As presented, HEART does neither. A set of goals could be defined under each category and neatly cascaded in to signals and metrics, and these might all look good on a dashboard. It would be easy for stakeholders to assume that as long as all these metrics head in the right direction, user experience is improving overall. This would be an easy mistake to make because metrics have a way of becoming the focus of decisions, rather than one source of information that feeds decisions. Having said that, improvement across the board is quite unlikely, more common is that some metrics improve while others decline. In this case the optimal decision is unclear because doing something to arrest decline in metric A could harm progress on metric B. Add to this the standard resource constraints of any team, and the next-best-action is unlikely to be clear. \textbf{What a better user experience means depends on the product, and the HEART framework is a useful step to clarifying this, but not the end. Information from outside the metrics must inform the measurement of overall progress. The framework could be improved by an additional column mapping dependenices and interactions between goals, to make clear the tradeoffs.}
  \item There is an undertone in the authors' presentation of the framework that data from web logs is `behavioural' simply because it represents actions taken by users in a natural, non-laboratory setting. While this kind of data does represent a user action (eg `user clicked back button in browser'), it gives only a very limited view of the underlying behaviour (eg `user is frustrated by workflow organisation in the product'). While a strength of the framework is its encouragement to think carefully about goals and their relevant signals, this view of data as `unfiltered' can be dangerous: no data is generated in isolation of important decisions by the product team over what to log and how. The danger is that one random decision by an engineer some time ago leads a particular set of data points to become \emph{the} relevant metric everyone focuses on, even if it is a poor proxy for the part of the user experience we care about improving. \textbf{This weakness can be guarded against by defining metrics broadly, in terms of the experience of the user that generated the data, rather than narrowly in terms of `we already pulled that out of the web logs'}.
\end{itemize}


\subsection{Shaun at Google}
\emph{If you worked at Google, which of their products would you like to work on most? Explain your answer.}

Google+, because I like a challenge! The promise of this product for me was always as an integration layer between all the Google services I already use. The failure of this product is a consequence, in my view, of trying to make it a mainstream social media channel, of which there were already too many. Despite several relaunches and at least two Executives in charge, Plus is still a bit confused: every time I visit plus.google.com it looks different. Now it includes a chat/Hangouts sidebar, and still shows the `Circles' I diligently defined years ago in anticipation of its promise to `share what you want with whom you want' (even though I've never used them).

As someone interested in developing my product management skills further, it would be a fascinating task to understand the intended role of Google+ within their ecosystem, test whether that role meets some unmet need of users, and proceed from that point of validated assumptions. Of course, I would have to enter that task willing to entertain the possiblity that there is no need for the product at all!

\section{Data, Data, Data}
If you had access to any dataset from any company or organization in the world...

\subsection{What would the company/dataset be?}
One dataset by itself is usually not as interesting as two datasets joined together. For this reason I'd like to cheat a little and give two answers:
\begin{itemize}
  \item All New Zealand property valuations and sale prices held by QV.co.nz, a government-owned company that charges steeply for access to data on individual properties
  \item Ownership data on properties in New Zealand
\end{itemize}

\subsection{What would you like to explore within the dataset?}

\subsection{Why this dataset/this exploration?}


\section{Technical Analytics Task}

\subsection{Context of the data}
Intercom launched the "Inbox Insights" feature in...

The aim of this feature is to make Intercom's customers...

The product team is interested in whether this feature has been successful, and whether there is scope for growing the business with the feature.

\subsection{Questions}

\subsubsection{What is the weekly adoption rate among Support Pro customers?}



%\includegraphics[scale=0.5]{figures/stations_with_problems_hist.pdf}
%\includepdf{figures/map_top_100.pdf}


\end{document}